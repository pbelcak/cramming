# single/multi GPU, sane(?) pytorch parameters
name: torch-default
defaults:
  - _default
  - _self_

mixed_precision: True # turns on AMP on GPUs/Intel devices. The default precision needs to be float
grad_scaling: True # Only activates when mixed_precision=True
mixed_precision_target_dtype: float16 # you might try your luck with bfloat16 too

# Distributed training:
zero_redundancy_optimizer: False # requires limited_decay_keys=[] for pytorch<=1.10.2
broadcast_buffers: False
bucket_cap_mb: 25
gradient_as_bucket_view: True
static_graph: False # turned off for inductor

# Misc:
foreach_optimizer: False

# Compilation
compile_torch: True
mode: "default" # can be overwritten by manual selection of inductor variables below # accuracy issues with max-autotune
dynamic: False # this is a world of pain (when I last tested it, around torch2.0 release)
fullgraph: False # why even compile when not compile everywhere :>
backend: inductor # use eager here when using the old bert-cX models
_inductor_vars: # boah better not elaborate this if you don't want to end up fighting the compiler internals over incomprehensible errors

# scaled dot products:
enable_mem_efficient_sdp: True
enable_math_sdp: True
enable_flash_sdp: True
